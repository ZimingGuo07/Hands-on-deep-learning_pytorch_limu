{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1、张量的创建\n",
      "tensor([7])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])\n",
      "tensor([[ 0.9985, -0.9339, -2.5359,  0.6142],\n",
      "        [ 0.7892, -0.8687,  1.2635, -0.3803],\n",
      "        [ 0.4767, -1.1482, -0.3057,  0.8225]])\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12],\n",
      "        [13, 14, 15, 16]])\n",
      "2、张量的运算\n",
      "tensor([ 6,  8, 10, 12])\n",
      "tensor([-4, -4, -4, -4])\n",
      "tensor([ 5, 12, 21, 32])\n",
      "tensor([0.2000, 0.3333, 0.4286, 0.5000])\n",
      "tensor([    1,    64,  2187, 65536])\n",
      "tensor([ 2.7183,  7.3891, 20.0855, 54.5981])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([[16, 17, 18, 19],\n",
      "        [20, 21, 22, 23],\n",
      "        [24, 25, 26, 27],\n",
      "        [28, 29, 30, 31]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19],\n",
      "        [20, 21, 22, 23],\n",
      "        [24, 25, 26, 27],\n",
      "        [28, 29, 30, 31]])\n",
      "tensor([[ 0,  1,  2,  3, 16, 17, 18, 19],\n",
      "        [ 4,  5,  6,  7, 20, 21, 22, 23],\n",
      "        [ 8,  9, 10, 11, 24, 25, 26, 27],\n",
      "        [12, 13, 14, 15, 28, 29, 30, 31]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n",
      "tensor(120)\n",
      "3、广播机制\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2]])\n",
      "tensor([[0, 1, 2, 3]])\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [1, 2, 3, 4],\n",
      "        [2, 3, 4, 5]])\n",
      "4、元素的访问 索引与切片\n",
      "tensor(0)\n",
      "tensor([ 8,  9, 10, 11])\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "tensor([[ 7,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[17, 17, 17,  3],\n",
      "        [17, 17, 17,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "5、节约内存（针对占用内存较大的数据）\n",
      "False\n",
      "True\n",
      "True\n",
      "6、转换成其他python类型\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]]) [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]] tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([17.7000]) 17.700000762939453 17.700000762939453 17\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#N维数组是机器学习和神经网络的主要数据结构\n",
    "import torch\n",
    "\n",
    "\n",
    "print(\"1、张量的创建\")\n",
    "#张量的一般创建\n",
    "x = [7]\n",
    "y = torch.tensor(x)# 通过提供包含数值的Python列表（或嵌套列表）来为所需张量中的每个元素赋予确定值\n",
    "print(y)\n",
    "\n",
    "#几种特殊的数组创建方式\n",
    "a = torch.zeros(3, 4)#创建一个3*4的张量，所有元素都是0\n",
    "print(a)\n",
    "\n",
    "b = torch.ones(3, 4)#创建一个3*4的张量，所有元素都是1\n",
    "print(b)\n",
    "\n",
    "c = torch.arange(1, 17)#创建一个一维张量，内容为[1,17)\n",
    "print(c)\n",
    "\n",
    "d = torch.randn(3, 4)#创建一个3*4的张量，每个元素都从均值为0、标准差为1的标准高斯（正态）分布中随机采样。\n",
    "print(d)\n",
    "\n",
    "#改变张量的形状\n",
    "e = c.reshape(4, 4)\n",
    "print(e)\n",
    "\n",
    "\n",
    "print(\"2、张量的运算\")\n",
    "#张量的标准运算\n",
    "m = torch.tensor([1, 2, 3, 4])\n",
    "n = torch.tensor([5, 6, 7, 8])\n",
    "print(m+n)\n",
    "print(m-n)\n",
    "print(m*n)\n",
    "print(m/n)\n",
    "print(m**n)#**运算符是求幂运算\n",
    "print(torch.exp(m))#按元素作指数运算\n",
    "\n",
    "#张量的连接\n",
    "i = torch.arange(16).reshape(4, 4)\n",
    "j = torch.arange(16, 32).reshape(4, 4)\n",
    "print(i)\n",
    "print(j)\n",
    "print(torch.cat((i, j), dim=0))#dim=0为按行合并，即每一行上的元素是不变的\n",
    "print(torch.cat((i, j), dim=1))#dim=1为按列合并，即每一列上的元素是不变的\n",
    "#以此类推，三维张量可以用dim=2合并\n",
    "\n",
    "'''\n",
    "通过比较、逻辑运算符构建二元张量\n",
    "比较运算符: ==  !=  >  <  >=  <=\n",
    "逻辑运算符: and（与）  or（或）  not（非）\n",
    "'''\n",
    "print(i==j)\n",
    "\n",
    "print(i.sum())#对张量中每一个元素求和\n",
    "\n",
    "\n",
    "print(\"3、广播机制\")\n",
    "p = torch.arange(0,3).reshape(3,1)\n",
    "q = torch.arange(0,4).reshape(1,4)\n",
    "print(p)\n",
    "print(q)\n",
    "print(p+q)#在计算p+q时，p复制产生了一个3*4的张量，q复制产生了一个3*4的张量，然后按元素相加\n",
    "\n",
    "\n",
    "print(\"4、元素的访问 索引与切片\")\n",
    "h = torch.arange(12).reshape(3,4)\n",
    "print(h[0, 0])#访问第0行第0列\n",
    "print(h[-1])#访问第-1行，即最后一行\n",
    "print(h[0:2])#访问第0、1行\n",
    "h[0, 0]=7#将元素写入矩阵\n",
    "print(h)\n",
    "h[0:2, 0:3]=17#将同一元素写入矩阵多个位置\n",
    "print(h)\n",
    "\n",
    "\n",
    "print(\"5、节约内存（针对占用内存较大的数据）\")\n",
    "t=torch.tensor([1, 2, 3, 4])\n",
    "T=torch.tensor([5, 6, 7, 8])\n",
    "id_t=id(t)\n",
    "t=t+T\n",
    "print(id_t==id(t))\n",
    "\n",
    "#使用X[:]=X+Y或者X+=Y可以节约内存\n",
    "t=torch.tensor([1, 2, 3, 4])\n",
    "T=torch.tensor([5, 6, 7, 8])\n",
    "id_t=id(t)\n",
    "t[:]=t+T\n",
    "print(id_t==id(t))\n",
    "\n",
    "t=torch.tensor([1, 2, 3, 4])\n",
    "T=torch.tensor([5, 6, 7, 8])\n",
    "id_t=id(t)\n",
    "t+=T\n",
    "print(id_t==id(t))\n",
    "\n",
    "\n",
    "print(\"6、转换成其他python类型\")\n",
    "X=torch.arange(16).reshape(4, 4)\n",
    "import numpy# numpy是python中最基础的多元数组的运算框架\n",
    "Y=X.numpy()#转换成numpy的多元数组\n",
    "Z=torch.tensor(Y)#转换成张量\n",
    "print(X, Y, Z)\n",
    "\n",
    "#将大小为1的张量转换成python标量\n",
    "a=torch.tensor([17.7])\n",
    "print(a, a.item(), float(a), int(a))\n",
    "print(type(a.item())==type(float(a)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(a): 2589715273184\n",
      "id(b): 2589715967648\n",
      "2589468624352\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "print(\"id(a):\",id(a))\n",
    "b=torch.arange(4,8)\n",
    "print(\"id(b):\",id(b))\n",
    "\n",
    "a=a+b\n",
    "print(id(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
